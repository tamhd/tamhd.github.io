<!DOCTYPE html>
<html>
<head>
<link rel="stylesheet" href="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
<link rel="stylesheet" type="text/css" href="index.css">
<title>Personal Page of Tam Hoang</title>
</head>
<body>


<div class='general'>

<p>I studied Mathematics, but that was a LONG time ago and it feels like another life now. This page is devoted to describe my experience with Computer Science (specifically Computational Linguistics).
</p>

<p>
I see myself as a drifter, who keeps bouncing from one facility to another. 
I have worked at <i>HMI Laboratory</i> @ UET, then <i>Institute of Formal and Applied Mathematics </i> @ Charles University in Prague and now <i>Computational Linguistics Laboratory</i> @ NUS. 
On the one hand, I am quite tired of moving. 
On the other hand, it provides me the opportunity to broaden my horizon (I think), alows me to work with a number of topics, in which the most notable ones are as follows.
</p>
<!--
<p><i> Working in the field of computational linguistics, but I'd like to become a generalist. 
I studied Mathematics and Computer Science, and I like to discuss other field of science as well. 
</i></p>
-->

<div class="interest">
  <h4>Question Answering: &nbsp;<button type="button" class="btn btn-primary btn-xs btn-info" data-toggle="collapse" data-target="#demoQA">Show/Hide</button></h4> 
  <div id="demoQA" class="collapse">
	<p>
	Question Answering, part of Natural Language Understanding, the designated topic which tries to fool users that they are communicating with an artificial intelligence when typing a search query in a box, was my first topic. I worked on three consecutive QA projects from 2010 to 2012. 
	</p>

	<p>
	I joined the first project when I was in the third year of my undegraduate programme.
	Supervised by professor <a href="http://uet.vnu.edu.vn/~sonpb/">Son Bao Pham</a>, our team (a research assistant and me) built a QA system for the <i>ecomonics and statistics-related domain</i>.
	An example of questions is like "How much does company X pay in taxes in 2012".
	We approached the problem with a rule-based approach and a set of mathematics formulae in programming language <a href="https://www.r-project.org/about.html">R</a>. 
	The flow was like this: <i>question -> pattern matching -> formula \& question entities -> execute the formula -> output</i>. It worked, so we completed the project. My colleague later extended the approach a bit (using machine learning with bag-of-words features). 
	</p>

	<p>
	The second topic, <i>Ontology-based QA System for Regulation</i>, was my bachelor thesis. 
	The premise of the project was to utilize knowledge representation for QA tasks. 
	We had to build a system which can prove that knowledge representation, such as Ontology OWL, is useful for question ansering. 
	The greatest challenged I faced in the project had to be the data transformation. 
	It was the task of creating an Ontology OWL format, which typically involved two entities being linked by a relation, from the regulation book, which, you know, contains something else.
	We tried several automatic and semi-automatic methods, none of them worked. 
	Hence, the data creation was done manually.
	As for the approach, we followed another work which converted the question into an intermediate representation (a tuples of entities), then extract related entities from the knowledge representation.
	</p>

	<p> The third project started after I graduated. I joined a project in collaboration between the HMI laboratory and JAIST. Well, there were only two people: a student who was doing his thesis, two of our supervisors and me. A key difference between this project and two other projects is the SQL database. After much discussion, we decided to utilize the name entity recognition and bipartite graph theory to solve the problem. It sounded legit. 
	However, the other guy quited after a few months. I carried out the work for another few months before we concluded that we needed more people. We halted the project after getting the first results. The report for our project got accepted to KSE 2015.
	</p>
  </div>
</div>


<div class="interest">
  <h4>Sentiment Analysis: &nbsp;<button type="button" class="btn btn-primary btn-xs btn-info" data-toggle="collapse" data-target="#demoSA">Show/Hide</button></h4> 
  <div id="demoSA" class="collapse">
	<p>
	Sentiment Analysis, or Opinion mining, the task you always do when reading feedbacks about the new iPhone before you buy it anyway, was one of my favourite.
	We made use of the movie reviews collection, trying to predict whether a review is positive or negative.
	The task is document-level sentiment analysis with just two classes. We primarily aimed to improve the quality of the binary classification by feature selection. We made that decision after admitting that no matter how many methods we tried (Naive Bayes, Random Forest, Majority Voting), they could not outperform the SVM learning method. 
	</p>

	<p>
	Fixed the bag of n-gram features, we mindlessly tried numerous feature selection techniques, including Information Gain, Chi-Square Statistics, Gini Index, etc. We also tried PCA (principle component analysis), the forward and backward feature selection. We also figured out that TF-IDF value did not work better than binary value and our datatset of 2000 instances was unstable. After a while, both my supervisor and I ran out of idea, so we stopped. 
	</p>

  </div>
</div>

<div class="interest">
  <h4>Information Retrieval: &nbsp;<button type="button" class="btn btn-primary btn-xs btn-info" data-toggle="collapse" data-target="#demoIR">Show/Hide</button></h4> 
  <div id="demoIR" class="collapse">
	<p>
	An IR-guy once told me: Information Retrieval is not Natual Language Processing. 
	Arguably, he was right. I came into contact with IR in several minor projects. 
	We did our assignment of the IR course by building an IR system based on feature space vectors, TF-IDF representation and cosine similarity. The result was greatly improved by the pivot method, which included the length factor in the similarity formula. On the other hand, query expansion and relevance feedback did not work very well in our experiments.
	</p>
	<p>
	I also used IR system to perform domain adaptation when I worked with statistical machine translation. I did not exploit the the IR system much. I used Lucene to index the collection (corpus) and setting weight to each keyword of the query.
	</p>
  </div>
</div>

<div class="interest">
  <h4>Statistical Machine Translation: &nbsp;<button type="button" class="btn btn-primary btn-xs btn-info" data-toggle="collapse" data-target="#demoSMT">Show/Hide</button></h4> 
  <div id="demoSMT" class="collapse">
	<p>
	Machine Translation, my lifelong love, the task when non-MT people constantly tell you "Why do you bother doing it, it is useless, Google Translate is already great". Hmm, they do have a point when everyone is trying to compare their results with Google's, don't we all?. 
	</p>

	<p>
	I started working on MT with a small project led by Dr. Ondrej Bojar, domain adaptation by selecting in-domain data. I later moved on to another project called Pivoting SMT, which was my master thesis. 
	We decided to build an SMT system for Czech and Vietnamese (both directions). Well, it had Vietnamese because I am Vietnamese. It has Czech because we were in the Czech Republic. Moreover, no one had worked on such a difficult language pair. It was difficult because not only the two language were totally different but also there were not enough data.
	</p>

	<p>
	I spent time playing with Moses, banging my head against EMAN. Simultaneously, we collect data for Czech and Vietnamese. The first experiments received an awful results, due to the high level of noise in the data. We later perform data cleaning. Then we implemented and tried out various methods for pivoting MT. Finally, my thesis was just a cookbook which describes all the potential methods to pivoting MT with example of Czech-Vietnamese translation. 
	</p>
  </div>
</div>

<div class="interest">
  <h4>Grammatical Error Correction: &nbsp;<button type="button" class="btn btn-primary btn-xs btn-info" data-toggle="collapse" data-target="#demoGEC">Show/Hide</button></h4> 
  <div id="demoGEC" class="collapse">
	<p>
	Gramatical Error Correction, when machine does the English proofreading, is my ongoing project. 
	</p>
  </div>
</div>

</div>

</body>
</html>